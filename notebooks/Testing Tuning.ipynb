{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from btb.tuning import Tunable\n",
    "from mlblocks import MLPipeline\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from orion import MLBLOCKS_PIPELINES\n",
    "from orion.evaluation import CONTEXTUAL_METRICS as METRICS"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 2,
=======
   "execution_count": 54,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "from orion.data import load_signal, load_anomalies\n",
    "\n",
    "signal = 'S-1'\n",
    "\n",
    "data = load_signal(signal)\n",
    "anomalies = load_anomalies(signal)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10149, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
=======
   "execution_count": 55,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "TRAIN: [ 5075  5076  5077 ... 10146 10147 10148] TEST: [   0    1    2 ... 5072 5073 5074]\n",
      "TRAIN: [   0    1    2 ... 5072 5073 5074] TEST: [ 5075  5076  5077 ... 10146 10147 10148]\n"
=======
      "TRAIN: [ 3383  3384  3385 ... 10146 10147 10148] TEST: [   0    1    2 ... 3380 3381 3382]\n",
      "TRAIN: [    0     1     2 ... 10146 10147 10148] TEST: [3383 3384 3385 ... 6763 6764 6765]\n",
      "TRAIN: [   0    1    2 ... 6763 6764 6765] TEST: [ 6766  6767  6768 ... 10146 10147 10148]\n"
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "def _expand(data, anomalies):\n",
    "    time_column = 'timestamp'\n",
<<<<<<< Updated upstream
    "    X = data.copy()\n",
    "\n",
    "    X = X.set_index(time_column)\n",
    "    X['label'] = [0] * len(X)\n",
    "    for i, anom in anomalies.iterrows():\n",
    "        X.loc[anom[0]: anom[1], 'label'] = 1\n",
    "\n",
    "    return X.reset_index()\n",
    "\n",
    "def _compress(data):\n",
    "    time_column = 'timestamp'\n",
    "    X = data.copy()\n",
    "    \n",
    "    X = X.set_index(time_column)\n",
    "    y = list()\n",
    "    \n",
    "    return anomalies\n",
=======
    "\n",
    "    data = data.set_index(time_column)\n",
    "    data['label'] = [0] * len(data)\n",
    "    for i, anom in anomalies.iterrows():\n",
    "        data.loc[anom[0]: anom[1], 'label'] = 1\n",
    "\n",
    "    return data.reset_index()\n",
    "\n",
    "def _compress(data):\n",
    "    time_column = 'timestamp'\n",
    "    label_column = 'label'\n",
    "\n",
    "    labels = np.split(data, np.flatnonzero(np.diff(data[label_column]) != 0) + 1)\n",
    "\n",
    "    anomalies = list()\n",
    "    for segment in labels:\n",
    "        if sum(segment[label_column]) == 0:\n",
    "            continue\n",
    "\n",
    "        interval = (segment.iloc[0][time_column], segment.iloc[-1][time_column])\n",
    "        anomalies.append(interval)\n",
    "\n",
    "    return pd.DataFrame(anomalies, columns=['start', 'end'])\n",
>>>>>>> Stashed changes
    "\n",
    "def _get_split(data, index):\n",
    "    X = data.iloc[index]\n",
    "    y = _compress(X)\n",
<<<<<<< Updated upstream
    "    return X, y\n",
    "\n",
    "n_splits = 2\n",
    "cv = KFold(n_splits=n_splits, shuffle=False, random_state=None)\n",
    "\n",
    "X = _expand(data, anomalies)\n",
    "for train_index, test_index in cv.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train = _get_split(data, train)\n",
    "    X_test = _get_split(data, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = _expand(data, anomalies)"
=======
    "    return X[columns], y\n",
    "\n",
    "n_splits = 3\n",
    "cv = KFold(n_splits=n_splits, shuffle=False, random_state=None)\n",
    "\n",
    "columns = data.columns\n",
    "data = _expand(data, anomalies)\n",
    "for train_index, test_index in cv.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, y_train = _get_split(data, train_index)\n",
    "    X_test, y_test = _get_split(data, test_index)"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame({\n",
    "    \"timestamp\": list(range(10)),\n",
    "    \"value\": [-9] * 10,\n",
    "    \"label\": [0, 0, 1, 1, 0, 0, 0, 1, 1, 1]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   timestamp  value  label\n",
      "0          0     -9      0\n",
      "1          1     -9      0\n",
      "4          4     -9      0\n",
      "5          5     -9      0\n",
      "6          6     -9      0\n",
      "\n",
      "   timestamp  value  label\n",
      "2          2     -9      1\n",
      "3          3     -9      1\n",
      "7          7     -9      1\n",
      "8          8     -9      1\n",
      "9          9     -9      1\n"
     ]
    }
   ],
   "source": [
    "list_of_df = [d for _, d in X.groupby('label')]\n",
    "print(*list_of_df, sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   timestamp  value  label\n",
      "0          0     -9      0\n",
      "1          1     -9      0\n",
      "\n",
      "   timestamp  value  label\n",
      "2          2     -9      1\n",
      "3          3     -9      1\n",
      "\n",
      "   timestamp  value  label\n",
      "4          4     -9      0\n",
      "5          5     -9      0\n",
      "6          6     -9      0\n",
      "\n",
      "   timestamp  value  label\n",
      "7          7     -9      1\n",
      "8          8     -9      1\n",
      "9          9     -9      1\n"
=======
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "TabError",
     "evalue": "inconsistent use of tabs and spaces in indentation (<ipython-input-60-130f221e17df>, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-60-130f221e17df>\"\u001b[0;36m, line \u001b[0;32m26\u001b[0m\n\u001b[0;31m    def _expand(self, data, anomalies):\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mTabError\u001b[0m\u001b[0;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
<<<<<<< Updated upstream
    "list_of_df = np.split(X, np.flatnonzero(np.diff(X.label) != 0) + 1)\n",
    "print(*list_of_df, sep=\"\\n\\n\")"
   ]
=======
    "\"\"\"Extension to Orion class\"\"\"\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from btb.tuning import Tunable, GPTuner\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from orion.core import Orion\n",
    "from orion.evaluation import CONTEXTUAL_METRICS as METRICS\n",
    "\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "class OrionExtended(Orion):\n",
    "    \"\"\"Extension of Orion Class.\n",
    "\n",
    "    The OrionExtended Class provides additional features of\n",
    "    tunning the pipeline.\n",
    "    \"\"\"\n",
    "    self._time_column = 'timestamp'\n",
    "    self._label_column = 'label'\n",
    "    self._columns = None\n",
    "    self._scorer = None\n",
    "    self.tuned = None\n",
    "\n",
    "\tdef _expand(self, data, anomalies):\n",
    "\t    data = data.set_index(self._time_column)\n",
    "\t    data[self._label_column] = [0] * len(data)\n",
    "\t    for i, anom in anomalies.iterrows():\n",
    "\t        data.loc[anom[0]: anom[1], self._label_column] = 1\n",
    "\n",
    "\t    return data.reset_index()\n",
    "\n",
    "\tdef _compress(self, data):\n",
    "\t    labels = np.split(data, np.flatnonzero(np.diff(data[self._label_column]) != 0) + 1)\n",
    "\n",
    "\t    anomalies = list()\n",
    "\t    for segment in labels:\n",
    "\t        if sum(segment[self._label_column]) == 0:\n",
    "\t            continue\n",
    "\n",
    "\t        interval = (segment.iloc[0][self._time_column], segment.iloc[-1][self._time_column])\n",
    "\t        anomalies.append(interval)\n",
    "\n",
    "\t    return pd.DataFrame(anomalies, columns=['start', 'end'])\n",
    "\n",
    "\tdef _get_split(self, data, index):\n",
    "\t    X = data.iloc[index]\n",
    "\t    y = _compress(X)\n",
    "\t    return X[self.columns], y\n",
    "\n",
    "    def _cv_split(self, data, anomalies, n_splits=3, random_state=None):\n",
    "    \tself.columns = data.columns\n",
    "\t\tdata = self._expand(data, anomalies)\n",
    "\n",
    "\t\tsplits = list()\n",
    "\t\tcv = KFold(n_splits=n_splits, random_state=random_state, shuffle=False)\n",
    "\t\tfor train_index, test_index in cv.split(X):\n",
    "\t\t    X_train, y_train = self._get_split(data, train_index)\n",
    "\t\t    X_test, y_test = self._get_split(data, test_index)\n",
    "\t\t    splits.append(X_train, y_train, X_test, y_test)\n",
    "\n",
    "\t\treturn splits\n",
    "\n",
    "\tdef scoring_function(self, data, anomalies, hyperparameters=None):\n",
    "        if hyperparameters:\n",
    "            self._mlpipeline.set_hyperparameters(hyperparameters)\n",
    "\n",
    "        scores = []\n",
    "        for X_train, y_train, X_test, y_test in get_splits(data, anomalies, 3):\n",
    "            self.fit(X_train)\n",
    "            detected = self.detect(X_test)\n",
    "            scores.append(self._scorer(y_test, detected, X_test))\n",
    "\n",
    "        return np.mean(scores)\n",
    "\n",
    "    def tune(self, data: pd.DataFrame, anomalies: pd.DataFrame,\n",
    "             scorer: str = 'f1', max_evals: int = 10, verbose: bool = False):\n",
    "        \"\"\"Fit and tune the pipeline to the given data.\n",
    "\n",
    "        Args:\n",
    "            data (DataFrame):\n",
    "                Input data, passed as a ``pandas.DataFrame`` containing\n",
    "                exactly two columns: timestamp and value.\n",
    "            anomalies (DataFrame):\n",
    "                Ground truth anomalies, passed as `pandas.DataFrame``\n",
    "                containing the start and end timestamps.\n",
    "        \"\"\"\n",
    "        self._scorer = METRICS[scorer]\n",
    "        self._mlpipeline = self._get_mlpipeline()\n",
    "\n",
    "        tunables = self._mlpipeline.get_tunable_hyperparameters(flat=True)\n",
    "        tunables = Tunable.from_dict(tunables)\n",
    "\n",
    "        default_score = self.scoring_function(data)\n",
    "        defaults = tunable.get_defaults()\n",
    "\n",
    "        tuner = GPTuner(tunable)\n",
    "        tuner.record(defaults, default_score)\n",
    "\n",
    "        best_score = default_score\n",
    "        best_proposal = defaults\n",
    "\n",
    "        for iteration in range(max_evals):\n",
    "            proposal = tuner.propose()\n",
    "            LOGGER.debug('Scoring proposal %s: %s', iteration, proposal)\n",
    "            try:\n",
    "                score = self.scoring_function(data, anomalies, proposal)\n",
    "                tuner.record(proposal, score)\n",
    "            except Exception as ex:\n",
    "                LOGGER.exception(\"Exception tuning pipeline %s\",\n",
    "                                 iteration, ex)\n",
    "\n",
    "            if score > best_score:\n",
    "                LOGGER.debug(\"New best found: {}\".format(score))\n",
    "                best_score = score\n",
    "                best_proposal = proposal\n",
    "\n",
    "        self._mlpipeline.set_hyperparameters(best_proposal)\n",
    "        self.tuned_params = best_proposal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> Stashed changes
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orion",
   "language": "python",
   "name": "orion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
